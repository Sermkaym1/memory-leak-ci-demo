"""
–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø–∞–º—è—Ç–∏ —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏
–î–æ–±–∞–≤–ª—è–µ—Ç –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Å–∏—Å—Ç–µ–º–Ω—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤, —Å–µ—Ç–µ–≤—ã—Ö —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π, —Ñ–∞–π–ª–æ–≤—ã—Ö –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä–æ–≤
"""
import psutil
import docker
import time
import json
from typing import Dict, List
from dataclasses import dataclass
from datetime import datetime


@dataclass
class SystemMetrics:
    """–°–∏—Å—Ç–µ–º–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞"""
    timestamp: float
    # –ü–∞–º—è—Ç—å
    rss_mb: float
    vms_mb: float
    memory_percent: float
    # CPU
    cpu_percent: float
    # –°–µ—Ç—å
    network_connections: int
    tcp_connections: int
    # –§–∞–π–ª—ã
    open_files: int
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ
    threads_count: int
    context_switches: int


class EnhancedMemoryMonitor:
    """
    –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø–∞–º—è—Ç–∏ —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏
    """
    
    def __init__(self, container):
        self.container = container
        self.container_name = container.name
        self.client = docker.from_env()
        self.metrics_history: List[SystemMetrics] = []
        print(f"‚úÖ EnhancedMemoryMonitor –¥–ª—è {self.container_name}")
    
    def get_detailed_metrics(self) -> SystemMetrics:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
        """
        try:
            # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
            stats = self.container.stats(stream=False)
            
            # –ü–∞—Ä—Å–∏–º –ø–∞–º—è—Ç—å
            memory_usage = stats['memory_stats']['usage']
            memory_limit = stats['memory_stats']['limit']
            memory_percent = (memory_usage / memory_limit) * 100
            
            rss_mb = memory_usage / (1024 * 1024)
            vms_mb = stats['memory_stats'].get('max_usage', memory_usage) / (1024 * 1024)
            
            # –ü–∞—Ä—Å–∏–º CPU
            cpu_delta = stats['cpu_stats']['cpu_usage']['total_usage'] - stats['precpu_stats']['cpu_usage']['total_usage']
            system_delta = stats['cpu_stats']['system_cpu_usage'] - stats['precpu_stats']['system_cpu_usage']
            cpu_percent = (cpu_delta / system_delta) * len(stats['cpu_stats']['cpu_usage']['percpu_usage']) * 100
            
            # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
            container_pid = self.container.attrs['State']['Pid']
            if container_pid:
                process = psutil.Process(container_pid)
                
                # –°–µ—Ç–µ–≤—ã–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
                connections = process.connections()
                tcp_connections = len([c for c in connections if c.type == psutil.SOCK_STREAM])
                
                # –û—Ç–∫—Ä—ã—Ç—ã–µ —Ñ–∞–π–ª—ã
                open_files = len(process.open_files())
                
                # –ü–æ—Ç–æ–∫–∏
                threads_count = process.num_threads()
                
                # –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
                ctx_switches = process.num_ctx_switches().voluntary + process.num_ctx_switches().involuntary
            else:
                # Fallback –∑–Ω–∞—á–µ–Ω–∏—è
                connections = []
                tcp_connections = 0
                open_files = 0
                threads_count = 1
                ctx_switches = 0
            
            metrics = SystemMetrics(
                timestamp=time.time(),
                rss_mb=rss_mb,
                vms_mb=vms_mb,
                memory_percent=memory_percent,
                cpu_percent=max(0, cpu_percent),  # –ù–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º
                network_connections=len(connections),
                tcp_connections=tcp_connections,
                open_files=open_files,
                threads_count=threads_count,
                context_switches=ctx_switches
            )
            
            self.metrics_history.append(metrics)
            return metrics
            
        except Exception as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –±–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
            return SystemMetrics(
                timestamp=time.time(),
                rss_mb=0.0,
                vms_mb=0.0,
                memory_percent=0.0,
                cpu_percent=0.0,
                network_connections=0,
                tcp_connections=0,
                open_files=0,
                threads_count=1,
                context_switches=0
            )
    
    def detect_memory_leak_patterns(self) -> Dict:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—ã —É—Ç–µ—á–µ–∫ –ø–∞–º—è—Ç–∏
        """
        if len(self.metrics_history) < 10:
            return {"status": "insufficient_data", "message": "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"}
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 10 –∏–∑–º–µ—Ä–µ–Ω–∏–π
        recent_metrics = self.metrics_history[-10:]
        
        # –†–æ—Å—Ç –ø–∞–º—è—Ç–∏
        memory_growth = recent_metrics[-1].rss_mb - recent_metrics[0].rss_mb
        
        # –†–æ—Å—Ç —Å–µ—Ç–µ–≤—ã—Ö —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π
        conn_growth = recent_metrics[-1].tcp_connections - recent_metrics[0].tcp_connections
        
        # –†–æ—Å—Ç —Ñ–∞–π–ª–æ–≤—ã—Ö –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä–æ–≤
        files_growth = recent_metrics[-1].open_files - recent_metrics[0].open_files
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø—ã —É—Ç–µ—á–µ–∫
        leak_types = []
        
        if memory_growth > 10:  # –†–æ—Å—Ç –ø–∞–º—è—Ç–∏ > 10 MB
            leak_types.append("memory_leak")
            
        if conn_growth > 5:  # –†–æ—Å—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π > 5
            leak_types.append("connection_leak")
            
        if files_growth > 10:  # –†–æ—Å—Ç —Ñ–∞–π–ª–æ–≤ > 10
            leak_types.append("file_descriptor_leak")
        
        # –ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–∞
        memory_values = [m.rss_mb for m in recent_metrics]
        trend = "increasing" if memory_values[-1] > memory_values[0] else "stable"
        
        return {
            "status": "analyzed",
            "leak_types": leak_types,
            "memory_growth_mb": memory_growth,
            "connection_growth": conn_growth,
            "files_growth": files_growth,
            "trend": trend,
            "severity": "high" if len(leak_types) >= 2 else "medium" if leak_types else "low"
        }
    
    def export_metrics_to_json(self, filename: str = None) -> str:
        """
        –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –≤ JSON –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        """
        if not filename:
            filename = f"metrics_{self.container_name}_{int(time.time())}.json"
        
        data = {
            "container": self.container_name,
            "monitoring_period": {
                "start": self.metrics_history[0].timestamp if self.metrics_history else time.time(),
                "end": self.metrics_history[-1].timestamp if self.metrics_history else time.time(),
                "duration_minutes": len(self.metrics_history) * 5 / 60  # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º –∏–∑–º–µ—Ä–µ–Ω–∏—è –∫–∞–∂–¥—ã–µ 5 —Å–µ–∫
            },
            "leak_analysis": self.detect_memory_leak_patterns(),
            "metrics": [
                {
                    "timestamp": m.timestamp,
                    "datetime": datetime.fromtimestamp(m.timestamp).isoformat(),
                    "memory": {
                        "rss_mb": m.rss_mb,
                        "vms_mb": m.vms_mb,
                        "percent": m.memory_percent
                    },
                    "cpu_percent": m.cpu_percent,
                    "network": {
                        "total_connections": m.network_connections,
                        "tcp_connections": m.tcp_connections
                    },
                    "files": {
                        "open_files": m.open_files
                    },
                    "system": {
                        "threads": m.threads_count,
                        "context_switches": m.context_switches
                    }
                }
                for m in self.metrics_history
            ]
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
        
        print(f"üìä –ú–µ—Ç—Ä–∏–∫–∏ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –≤ {filename}")
        return filename
    
    def print_summary(self):
        """
        –í—ã–≤–æ–¥–∏—Ç –∫—Ä–∞—Ç–∫—É—é —Å–≤–æ–¥–∫—É –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
        """
        if not self.metrics_history:
            print("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
            return
        
        first = self.metrics_history[0]
        last = self.metrics_history[-1] 
        
        print(f"\nüìä –°–í–û–î–ö–ê –ú–û–ù–ò–¢–û–†–ò–ù–ì–ê: {self.container_name}")
        print("=" * 60)
        print(f"‚è±Ô∏è  –ü–µ—Ä–∏–æ–¥ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞: {len(self.metrics_history)} –∏–∑–º–µ—Ä–µ–Ω–∏–π")
        print(f"üìà –ü–∞–º—è—Ç—å RSS: {first.rss_mb:.1f} ‚Üí {last.rss_mb:.1f} MB (Œî{last.rss_mb-first.rss_mb:+.1f})")
        print(f"üíæ –ü–∞–º—è—Ç—å VMS: {first.vms_mb:.1f} ‚Üí {last.vms_mb:.1f} MB (Œî{last.vms_mb-first.vms_mb:+.1f})")
        print(f"üîó TCP —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è: {first.tcp_connections} ‚Üí {last.tcp_connections} (Œî{last.tcp_connections-first.tcp_connections:+d})")
        print(f"üìÅ –û—Ç–∫—Ä—ã—Ç—ã–µ —Ñ–∞–π–ª—ã: {first.open_files} ‚Üí {last.open_files} (Œî{last.open_files-first.open_files:+d})")
        print(f"üßµ –ü–æ—Ç–æ–∫–∏: {first.threads_count} ‚Üí {last.threads_count} (Œî{last.threads_count-first.threads_count:+d})")
        
        # –ê–Ω–∞–ª–∏–∑ —É—Ç–µ—á–µ–∫
        leak_analysis = self.detect_memory_leak_patterns()
        print(f"\nüéØ –ê–ù–ê–õ–ò–ó –£–¢–ï–ß–ï–ö:")
        print(f"   –°–µ—Ä—å–µ–∑–Ω–æ—Å—Ç—å: {leak_analysis.get('severity', 'unknown')}")
        print(f"   –¢–∏–ø—ã —É—Ç–µ—á–µ–∫: {', '.join(leak_analysis.get('leak_types', []))}")
        print(f"   –¢—Ä–µ–Ω–¥: {leak_analysis.get('trend', 'unknown')}")
        print("=" * 60)


# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ —Ç–µ—Å—Ç–∞—Ö
if __name__ == "__main__":
    # –î–µ–º–æ –±–µ–∑ —Ä–µ–∞–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
    print("üß™ –î–µ–º–æ EnhancedMemoryMonitor")
    
    # –°–æ–∑–¥–∞–µ–º —Ñ–µ–π–∫–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
    class FakeContainer:
        name = "demo-container"
    
    monitor = EnhancedMemoryMonitor(FakeContainer())
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    for i in range(20):
        metrics = SystemMetrics(
            timestamp=time.time() + i * 10,
            rss_mb=50 + i * 2,  # –†–æ—Å—Ç –ø–∞–º—è—Ç–∏
            vms_mb=200 + i * 1.5,
            memory_percent=20 + i * 0.5,
            cpu_percent=15.0,
            network_connections=10 + i,  # –†–æ—Å—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π
            tcp_connections=5 + i // 2,
            open_files=20 + i,  # –†–æ—Å—Ç —Ñ–∞–π–ª–æ–≤
            threads_count=4,
            context_switches=1000 + i * 10
        )
        monitor.metrics_history.append(metrics)
    
    # –í—ã–≤–æ–¥–∏–º —Å–≤–æ–¥–∫—É
    monitor.print_summary()
    
    # –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º –≤ JSON
    json_file = monitor.export_metrics_to_json("demo_metrics.json")
    print(f"‚úÖ –°–æ–∑–¥–∞–Ω —Ñ–∞–π–ª: {json_file}")